{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eio-lab6","provenance":[{"file_id":"1CmRdV8KkPf9j0DDk_bC8IT6SLPbRM1vG","timestamp":1611429341109},{"file_id":"1QpsxkPhAE-EgfwYsOsRPd_KobYhyFan9","timestamp":1572989882145},{"file_id":"1YyS2vvPmtCATqCXPNrdic-aKZxtdm35j","timestamp":1572989874798},{"file_id":"1aknfFPOfmvYFqJdqkyaHQLjomDNh4KpT","timestamp":1572989868630},{"file_id":"1XAUKPGNFNzkiuiNUTFGzxJh3VxFAWamq","timestamp":1572989860085}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ebvqJaNU9bkH"},"source":["# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n","\n","\n","---\n","\n","**Prowadzący:** Jakub Bednarek<br>\n","**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n","**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"i0tVMrm99g5w"},"source":["## Uwaga\n","\n","* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n","* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"]},{"cell_type":"markdown","metadata":{"id":"Wlq47LA0BuBB"},"source":["## Cel ćwiczeń:\n","- zapoznanie się z rekurencyjnymi sieciami neuronowymi,\n","- stworzenie modelu sieci z warstwami rekurencyjnymi dla zbioru danych MNIST,\n","- stworzenie własnych implementacji warstwami neuronowych"]},{"cell_type":"code","metadata":{"id":"SxLU8paIDmUe","executionInfo":{"status":"ok","timestamp":1611429362736,"user_tz":-60,"elapsed":2470,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"scL5_bHTD-M7","executionInfo":{"status":"ok","timestamp":1611429371015,"user_tz":-60,"elapsed":593,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}}},"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, LSTM, LSTMCell, SimpleRNNCell\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adadelta, RMSprop\n","from tensorflow.python.keras import backend as K"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV_u-YBWEJ8X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611429410712,"user_tz":-60,"elapsed":1335,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"915bc9c0-2956-4489-fc70-cd103f2bf000"},"source":["(x_tr, y_tr), (x_te, y_te) = mnist.load_data()\n","x_tr = x_tr.astype('float32') # shape: 60000, 28, 28\n","x_te = x_te.astype('float32') # shape: 10000, 28, 28\n","x_tr /= 255  # normalizacja wartości do przedziału [0, 1]\n","x_te /= 255\n","y_tr = to_categorical(y_tr, 10)  # zamiana etykiety na one-hot encoding; np. 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","y_te = to_categorical(y_te, 10)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ppmDSGoyFuJ9"},"source":["## Sieci rekurencyjne\n","http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","\n","https://www.tensorflow.org/guide/keras/rnn\n","\n","https://www.tensorflow.org/guide/function\n","\n","http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n","\n","http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n","\n","Przykładowy model z warstwą rekurencyjną dla danych MNIST:"]},{"cell_type":"code","metadata":{"id":"ViqotGlHGy9t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611429555721,"user_tz":-60,"elapsed":104132,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"24442ca1-df10-44c5-da2c-ecf917d90835"},"source":["class RecurrentModel(Model):\n","    def __init__(self, num_classes=10):\n","        super().__init__(name='my_model')\n","        self.num_classes = num_classes\n","        self.lstm_1 = LSTM(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        x = self.lstm_1(inputs)\n","        return self.dense_1(x)\n","\n","model = RecurrentModel(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 52s 27ms/step - loss: 1.1463 - accuracy: 0.6448\n","Epoch 2/2\n","1875/1875 [==============================] - 51s 27ms/step - loss: 0.1589 - accuracy: 0.9538\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7af0859ef0>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ZgtZzVYg1361"},"source":["### Zadanie 1\n","Rozszerz model z powyższego przykładu o kolejną warstwę rekurencyjną przed gęstą warstwą wyjściową.\n","\n","Standardowe sieci neuronowe generują jeden wynik na podstawie jednego inputu, natomiast sieci rekurencyjne przetwarzają dane sekwencyjnie, w każdym kroku łącząc wynik poprzedniego przetwarzania i aktualnego wejścia. Dlatego domyślnym wejściem sieci neuronowej jest tensor 3-wymiarowy ([batch_size,sequence_size,sample_size]).\n","Domyślnie warstwy rekurencyjne w Kerasie zwracają tylko wyniki przetwarzania ostatniego\n","kroku (otrzymują tensor 3-wymiarowy, zwracają tensor 2-wymiarowy). Jeśli chcesz zwrócić sekwencje wyników wszystkich kroków przetwarzania dla warstwy rekurencyjnej, musisz ustawić parametr return_sequences=True.\n"]},{"cell_type":"code","metadata":{"id":"MSJUzxAc15uZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611429799401,"user_tz":-60,"elapsed":224442,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"0f1f1b74-b8ad-4796-dca5-57ef608d722e"},"source":["class Model1(Model):\n","    def __init__(self, num_classes):\n","        super().__init__(name='Model1')\n","        self.num_classes = num_classes\n","        self.lstm_1 = LSTM(128, activation='relu', return_sequences=True)\n","        self.lstm_2 = LSTM(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        x = self.lstm_1(inputs)\n","        x = self.lstm_2(x)\n","        return self.dense_1(x)\n","\n","model = Model1(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 112s 59ms/step - loss: 1.1394 - accuracy: 0.6693\n","Epoch 2/2\n","1875/1875 [==============================] - 112s 60ms/step - loss: 0.1497 - accuracy: 0.9582\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7ae861d0f0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"fYDLWjdseB4H"},"source":["### Zadanie 2 \n","Wykorzystując model z przykładu, napisz sieć rekurencyjną przy użyciu SimpleRNNCell.\n","\n","Cell implementuje tylko operacje wykonywane przez warstwę\n","rekurencyjną dla jednego kroku. Warstwy rekurencyjne w każdym kroku\n","łączą wynik operacji poprzedniego kroku i aktualny input.\n","Wykorzystaj pętle for do wielokrotnego wywołania komórki SimpleRNNCell (liczba kroków to liczba elementów w sekwencji). Aby wywołać SimpleRNNCell dla pojedynczego wejścia i stanu należy użyć jej metody ```call``` analogicznie jak w przypadku własnych modeli (tzn. ```my_model(input)```). \n","\n","\n","\n","Wywołanie zainicjalizowanej komórki rekurencyjnej wymaga podania aktualnego inputu i **listy macierzy** (w dokumentacji jest błąd, że ma to być macierz) stanów ukrytych poprzedniego kroku (SimpleRNNCell ma jeden stan, LSTMCell w następnym zadaniu ma dwa stany).\n","\n","Trzeba zainicjalizować ukryty stan warstwy wartościami początkowymi (można wykorzystać rozkład normalny - tf.random.normal)."]},{"cell_type":"code","metadata":{"id":"6yZ8yKmbee44","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611429824627,"user_tz":-60,"elapsed":25214,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"da1f42eb-3cc2-481b-d5d2-b6391d85defe"},"source":["class Model2(Model):\n","    def __init__(self, num_classes):\n","        super().__init__(name='Model2')\n","        self.num_classes = num_classes\n","        self.cell = SimpleRNNCell(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        h = tf.random.normal([inputs.shape[0], self.cell.units])\n","        for i in range(inputs.shape[1]):\n","          x, h = self.cell(inputs[:,i,:], h)\n","        return self.dense_1(x)\n","\n","model = Model2(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 13s 6ms/step - loss: 0.7982 - accuracy: 0.7297\n","Epoch 2/2\n","1875/1875 [==============================] - 11s 6ms/step - loss: 0.2206 - accuracy: 0.9343\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7ae61ca278>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"eyPGkC6oiEd5"},"source":["### Zadanie 3\n","Zamień komórkę rekurencyjną z poprzedniego zadania na LSTMCell (LSTMCell ma dwa stany ukryte)."]},{"cell_type":"code","metadata":{"id":"C5MPQ1UcigN5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611431645762,"user_tz":-60,"elapsed":92844,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"1a0bef68-93f8-42d2-cf25-aee081fea855"},"source":["class Model3(Model):\n","    def __init__(self, num_classes):\n","        super().__init__(name='Model3')\n","        self.num_classes = num_classes\n","        self.cell = LSTMCell(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        shape = (inputs.shape[0], self.cell.units)\n","        h = [tf.random.normal(shape), tf.random.normal(shape)]\n","        for i in range(inputs.shape[1]):\n","          x, h = self.cell(inputs[:,i,:], h)\n","        return self.dense_1(x)\n","\n","model = Model3(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 48s 24ms/step - loss: 1.2776 - accuracy: 0.6218\n","Epoch 2/2\n","1875/1875 [==============================] - 44s 23ms/step - loss: 0.1583 - accuracy: 0.9549\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7aea6a7908>"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"prwjaEv2efs3"},"source":["### Zadanie 4\n","Wykorzystując model z poprzedniego zadania, stwórz model sieci\n","neuronowej z własną implementacją prostej warstwy rekurencyjnej.\n","- w call zamień self.lstm_cell_layer(x) na wywołanie własnej metody np. self.cell(x)\n","- w konstruktorze modelu usuń inicjalizację komórki LSTM i zastąp ją inicjalizacją warstw potrzebnych do stworzenia własnej komórki rekurencyjnej,\n","- stwórz metodę cell() wykonującą operacje warstwy rekurencyjnej,\n","- prosta warstwa rekurencyjna konkatenuje poprzedni wyniki i aktualny input, a następnie przepuszcza ten połączony tensor przez warstwę gęstą (Dense)."]},{"cell_type":"code","metadata":{"id":"BGQr50EafxSH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611431673414,"user_tz":-60,"elapsed":120473,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"00460c93-f181-4ab6-cd62-2972c2e8b6b0"},"source":["class Model4(Model):\n","    def __init__(self, num_classes):\n","        super().__init__(name='Model4')\n","        self.num_classes = num_classes\n","        self._cell = Dense(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def cell(self, x, h):\n","        return self._cell(K.concatenate([x, h]))\n","\n","    def call(self, inputs):\n","        h = tf.random.normal((inputs.shape[0], self._cell.units))\n","        for i in range(inputs.shape[1]):\n","          h = self.cell(inputs[:,i,:], h)\n","        return self.dense_1(h)\n","\n","model = Model4(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 14s 7ms/step - loss: 0.8494 - accuracy: 0.7116\n","Epoch 2/2\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.2451 - accuracy: 0.9280\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7aea153710>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"_3sOaUu3b77l"},"source":["### Zadanie 5\n","\n","Na podstawie modelu z poprzedniego zadania stwórz model z własną implementacją warstwy LSTM. Dokładny i zrozumiały opis działania warstwy LSTM znajduje się na [stronie](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."]},{"cell_type":"code","metadata":{"id":"Kyu4YijDcA13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611432334355,"user_tz":-60,"elapsed":76801,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnYXiO1WyUqmQTRdZRyU1OAxXlwLrQ5Ovpf1VieQ=s64","userId":"05648663591110704065"}},"outputId":"ea939521-2b50-4de5-cc50-cf74da46341f"},"source":["class Model5(Model):\n","    def __init__(self, num_classes):\n","        super().__init__(name='Model5')\n","        self.num_classes = num_classes\n","        self.units = 128\n","        self.dense_i = Dense(self.units, activation='sigmoid')\n","        self.dense_f = Dense(self.units, activation='sigmoid')\n","        self.dense_o = Dense(self.units, activation='sigmoid')\n","        self.dense_c = Dense(self.units, activation='tanh')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def cell(self, x, h):\n","        c_last, h_last = h\n","        hx = K.concatenate([h_last, x])\n","        c_next = self.dense_f(hx)*c_last + self.dense_i(hx)*self.dense_c(hx)\n","        h_next = self.dense_o(hx)*K.tanh(c_next)\n","        return h_next, (c_next, h_next)\n","\n","    def call(self, inputs):\n","        shape = (inputs.shape[0], self.units)\n","        h = [tf.random.normal(shape), tf.random.normal(shape)]\n","        for i in range(inputs.shape[1]):\n","          x, h = self.cell(inputs[:,i,:], h)\n","        return self.dense_1(x)\n","\n","model = Model5(num_classes=10)\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_tr, y_tr, batch_size=32, epochs=2)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 40s 19ms/step - loss: 0.6215 - accuracy: 0.7974\n","Epoch 2/2\n","1875/1875 [==============================] - 36s 19ms/step - loss: 0.1355 - accuracy: 0.9617\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7ad432d978>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"BXGn_ZuguP43"},"source":[""],"execution_count":null,"outputs":[]}]}