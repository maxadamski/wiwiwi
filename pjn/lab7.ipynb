{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"Lab7-done.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nuVFyvmTZF_8","colab_type":"text"},"source":["# Zaawansowane sieci neuronowe w detekcji sentymentu\n","\n","Na dzisiejszych laboratoriach skupimy się na wykorzystaniu zaawansowanych architektur sieci neuronowych do problemu wykrywania sentymentu (emocji: pozytywnych i negatywnych), które zawarte są w tekstach.\n","\n","Ponieważ implementacja sieci LSTM i GRU jest dość trudna/czasochłonna - wykorzystamy gotowy framework, który pozwoli nam na zdefiniowanie i wyuczenie sieci neuronowej na wysokim poziomie - **Keras**.\n","\n","Ocenę sentymentu przeprowadzimy na gotowym zbiorze recenzji z portalu IMDB, który jest już odpowiednio przeprocesowany i posiada zdefiniowany oczekiwany sentyment dla każdego tekstu (a więc dla którego bez wysiłku możemy uruchomić algorytmy klasyfikacji i je ocenić). Zaczynajmy!"]},{"cell_type":"markdown","metadata":{"id":"7KmBSKA0ZF_9","colab_type":"text"},"source":["## Dane do uczenia\n","\n","Poniższy fragment kodu pobiera dane do uczenia. Funkcja imdb.load_data() ładuje zarówno zbiór uczący (wektory cech, oraz etykiety), jak i analogiczny zbiór testowy. \n","\n","Poniżej wyświetlony na ekranie jest jeden z przykładów uczących oraz przypisana do niego etykieta.\n","\n","Widzimy, że tekst reprezentowany jest sekwencją liczb. Co one oznaczają?\n","Każda liczba reprezentuje słowo (jest identyfikatorem słowa), identyfikatory posortowane są względem częstości występowania słów, zatem słowo o identyfikatorze 10 występuje w korpusie częśćiej niż słowo o identyfikatorze 11.\n","Dodatkowo wprowadzone są specjalne znaczniki BOS - początek zdania i EOS - koniec zdania. Oba równiez reprezentowane są w formie liczbowej.\n","\n","Pamiętamy z jednych z pierwszych laboratoriów, że duża wielkość słownika jest problematyczna. Dobrym pomysłem jest często odrzucenie najrzadziej wystepujących słów, ponieważ one nie mają wielkiego znaczenia (Kiedy uczymy się nowego języka - często nie rozumiemy pojedynczych słów, ale znajomość pozostałych sprawia, że jesteśmy w stanie zrozumieć sens tekstu). Aby ograniczyć rozmiar słownika, w funkcji load_data() możemy zadać parametr num_words o określonej wartości. Wartość ta, mówi nam ile najczęściej występujących słów bierzemy pod uwagę. Wszystkie rzadsze słowa - reprezentowane są zbiorczo taką samą wartością liczbową oznaczającą nieznany token (Unknown token).\n","\n","Inną ważną kwestią jest długość recenzji - każda z nich może składać się z innej liczby słów. O ile sieci rekurencyjne są teoretycznie w stanie poradzić sobie z sekwencjami o różnej długości, to w praktyce optymalizacje wymagają, aby sekwencje były reprezentowane poprzez taką samą długość wektora cech. Aby wyrównać liczbę cech na wejściu stosuje się tzw. padding do określonej długości. Jeśli wektor cech recenzji jest dłuższy niż zadany padding - zostaje on ucięty, jeśli zaś jest krótszy - dodawane są cechy o wartości 0, aby dopełnić długości.\n","\n","**Zadanie 1 (1.25 punktu)**: Poniższy kod pobiera dane z IMDB ograniczając liczbę słów w słowniku do 10000. \n","Chcielibyśmy przyjrzeć się danym oraz zastosować na nich padding. Aby to zrobić - wykonajmy następujące kroki:\n","<ol>\n","    <li>Sprawdźmy i wyświetlmy średnią długość wektora w x_train - pozwoli nam to sprawdzić ile średnio słów jest w recenzji</li>\n","    <li>Sprawdźmy i wyświetlmy odchylenie standardowe wektora x_train - pozwoli nam to określić jak wygląda rozrzut wartości od średniej</li>\n","    <li>Stosując funkcję pad_sequences z kerasa (zaimportowana w pierwszej linijce) - nadpiszmy zbiory x_train i x_test tak, aby każdy wektor miał długość 500 (https://keras.io/preprocessing/sequence/). Wybrana długość wynika z analizy z poprzednich podpunktów (średnia i odch. std.). Jak teraz wygląda średnia długość i odchylenie std?</li>\n","    <li>Nasz model będziemy weryfikować na zbiorze testowym z użyciem miary accuracy (jaki % podjętych przez klasyfikator decyzji jest poprawnych). Warto sprawdzić jak wygląda rozkład etykiet w zbiorze testowym. Sprawdź: jaki procent zbioru testowego stanowią etykiety o wartości 1? jaki procent zbioru testowego stanowią etykiety o wartości 0?\n","</ol>"]},{"cell_type":"code","metadata":{"id":"nM8Myk9ab_Rf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"2760029b-bad9-4e45-84af-68d6ec663fa5","executionInfo":{"status":"ok","timestamp":1589129119286,"user_tz":-120,"elapsed":6091,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.datasets import imdb\n","import numpy as np\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","print(x_train[0]) # pokaż wektor cech dla pierwszej recenzji\n","print(y_train[0]) # pokaż etykietę (1 = sentyment pozytywny; 0 = sentyment negatywny)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lyEgcJKMZF_-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"8b768e25-16f5-4c94-cbdf-ec79a72c8b88","executionInfo":{"status":"ok","timestamp":1589129895564,"user_tz":-120,"elapsed":711,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["average_x_len = np.mean([len(x) for x in x_train]) # TODO: oblicz średnią liczbę cech w wektorach x_train (możesz wykorzystać numpy)\n","stddev_x_len = np.std([len(x) for x in x_train]) # TODO: oblicz odchylenie standardowe po x_train (możesz wykorzystać numpy)\n","\n","x_train = pad_sequences(x_train, 500) # TODO: zastosuj padding do 500 tokenów (wskazówka: zobacz na listę importowanych funkcji)\n","x_test = pad_sequences(x_test, 500)   # TODO: zastosuj padding do 500 tokenów\n","\n","padded_average_x_len = np.mean([len(x) for x in x_train]) # TODO: oblicz średnią liczbę cech w wektorach x_train po paddingu\n","padded_stddev_x_len = np.std([len(x) for x in x_train]) # TODO: oblicz odchylenie standardowe po x_train po paddingu\n","\n","counts = dict(zip(*np.unique(y_test, return_counts=True)))\n","count_positive = counts[1] # TODO: ile elementów testowych ma przypisany sentyment pozytywny\n","count_negative = counts[0] # TODO: ile elementów testowych ma przypisany sentyment negatywny\n","\n","print(\"Przed paddingiem. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n","    ave_len=average_x_len, std_dev=stddev_x_len))\n","\n","print(\"Po paddingu. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n","    ave_len=padded_average_x_len, std_dev=padded_stddev_x_len))\n","\n","print(\"W zbiorze testowym jest {pos} elementów o pozytywnym sentymencie i {neg} elementów o negatywnym. Sentyment pozytywny stanowi {percentage}% zbioru.\".format(\n","pos=count_positive, neg=count_negative, percentage = 100.0*(count_positive)/(count_positive + count_negative)))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Przed paddingiem. Średnia długość wektora: 500.0; odchylenie std: 0.0\n","Po paddingu. Średnia długość wektora: 500.0; odchylenie std: 0.0\n","W zbiorze testowym jest 12500 elementów o pozytywnym sentymencie i 12500 elementów o negatywnym. Sentyment pozytywny stanowi 50.0% zbioru.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"78CFOYmdZGAA","colab_type":"text"},"source":["## Przykładowa prosta sieć w Keras.\n","Poniżej znajdziecie przykład kodu, którzy tworzy sieć dwuwarstwową o:\n","<ol>\n","<li>100 wejściach</li>\n","<li>warstwie ukrytej z 64 neuronami o aktywacji ReLU</li>\n","<li>warstwie wyjściowej z 1 neuronem o aktywacji sigmoidalnej</li>\n","</ol>\n","Ten kod będzie szablonem dla kolejnych zdań. Uruchom go i sprawdź jak prosta sieć działa \n","\n","$ReLU(x) = max(0, x)$, "]},{"cell_type":"code","metadata":{"id":"XCO-PJElZGAB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":242},"outputId":"cd397323-3b24-4d72-e2a7-4a2fc5a25ab9","executionInfo":{"status":"ok","timestamp":1589129940663,"user_tz":-120,"elapsed":25646,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["import numpy as np\n","np.random.seed(1337) # for reproducibility\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Embedding, LSTM, GRU, Conv1D, MaxPooling1D\n","\n","\n","model = Sequential() # sequential = sieć jako lista warstw, dodajemy warstwy metodą .add() (jak w standardowej liście)\n","model.add(Dense(units=64, input_dim=500, activation='relu')) # dodajemy warstwę Dense (gęstą). Dense oznacza, że wszystkie wejścia (w tym przypadku 100) połączone są z neuronami warstwy w sposób każdy z każdym (każdy neuron z poprzedniej warstwy połączony z każdym neuronem warstwy następnej, tak jak to robiliśmy na poprzednich laboratoriach)\n","model.add(Dense(units=1, activation='sigmoid')) # rozmiar wejścia zdefiniować musimy tylko w pierwszej warstwie (definiujemy ile jest cech na wejściu). Ponieważ model wie jakie są rozmiary poprzednich warstw - może w sposób automatyczny odkryć, że opprzednia warstwa generuje 64 wyjścia\n","\n","model.compile(loss='binary_crossentropy', # budujemy model! ustawiamy funkcję kosztu - mamy klasyfikację z dwiema etykietami, więc stosujemy 'binary_crossentropy'\n","              optimizer='adam',  # wybieramy w jaki sposób sieć ma się uczyć\n","              metrics=['accuracy']) # i wybieramy jaka miara oceny nas interesuje\n","\n","\n","model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test)) # uczymy model na zbiorze treningowym, weryfikujemy na testowym, epochs - oznacza ile przejść po wszystkich przykładachw zbiorze uczącym powinno się wykonać.\n","\n","loss, accuracy = model.evaluate(x_test, y_test, batch_size=128) # ostateczna ewaluacja wyuczonego modelu\n","print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "],"execution_count":33,"outputs":[{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/5\n","25000/25000 [==============================] - 5s 190us/step - loss: 100.8503 - accuracy: 0.5010 - val_loss: 6.2868 - val_accuracy: 0.5005\n","Epoch 2/5\n","25000/25000 [==============================] - 3s 117us/step - loss: 2.7351 - accuracy: 0.5107 - val_loss: 1.7895 - val_accuracy: 0.4983\n","Epoch 3/5\n","25000/25000 [==============================] - 3s 118us/step - loss: 1.1170 - accuracy: 0.5071 - val_loss: 1.2156 - val_accuracy: 0.5014\n","Epoch 4/5\n","25000/25000 [==============================] - 3s 119us/step - loss: 0.8237 - accuracy: 0.5120 - val_loss: 1.0892 - val_accuracy: 0.4982\n","Epoch 5/5\n","25000/25000 [==============================] - 3s 119us/step - loss: 0.7342 - accuracy: 0.5143 - val_loss: 1.0541 - val_accuracy: 0.4970\n","25000/25000 [==============================] - 0s 11us/step\n","Trafność klasyfikacji to: 49.696001410484314%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2GFXMqdYZGAD","colab_type":"text"},"source":["Jak widzimy, sieć generuje trafność na poziomie 50%. Ponieważ zarówno etykieta \"1\", jak i \"0\" w zbiorze testowym stanowią połowę - wiemy, że ten klasyfikator nie jest najlepszy (Taką samą trafność będą miały klasyfikatory: zwracające zawsze etykietę 0, zwracajace zawsze etykietę 1 oraz zwracające decyzje losowe).\n","\n","Czy jesteśmy w stanie coś z tym zrobić? \n","Tak. Nasza poprzednia sieć próbowała uczyć się z listy identyfikatorów słów, to stosunkowo kiepska reprezentacja, ale pamiętamy, że całkiem nieźle sprawowały się tzw. Embeddingi. Szczęśliwie - keras udostępnia warstwy uczące się embeddingów z reprezentacji takiej, którą dotychczas podawaliśmy na wejściu.\n","\n","\n","\n","**Zadanie 2 (1.25 punktu) - Wykorzystanie embeddingów w sieci feed forward**\n","Widząc w jaki sposób dodawane są kolejne warstwy w Kerasie (model.add(...)), przerób architekturę istniejącej sieci w następujący sposób:\n","\n","<ol>\n","    <li>Pierwsza warstwa: Warstwa Embedding (https://keras.io/layers/embeddings/), ustaw długość generowanego wektora na 32, długość wejścia - taka jak wynika to z paddingu - 500, a także rozmiar słownika zgodny z tym co wybraliśmy przy pobieraniu danych (10000)</li>\n","    <li>Druga warstwa: Flatten (https://keras.io/layers/core/); Zauważmy, że warstwa ucząca embeddingi - Embedding - zamienia nam każdy indentyfikator z wektora wejściowego na wektor o zadanej liczbie wymiarów. Każde słowo reprezentowane jest teraz nie pojedynczą liczbą a pojedynczym wektorem. Kiedy złożymy embeddingi wszystkich słów otrzymamy macierz wielkości: liczba słów x rozmiar embeddingu. Warstwa Flatten nie robi nic poza tym, że bierze taką macierz i zamienia znów na wektor poprzez połączenie ze sobą wszystkich wektorów embeddingów w jeden wielki wektor (ustawiając je w jednym wymiarze jeden za drugim) </li>\n","    <li>Trzecia warstwa: klasyczna warstwa Dense (https://keras.io/layers/core/) np. z 64 neuronami i aktywacją relu\n","    <li>Czwarta warstwa (wyjściowa): klasyczna warstwa Dense z 1 neuronem (generującym prawdopodobieństwo pozytywnego sentymentu) i aktywacją sigmoidalną (sigmoid)\n","</ol>\n","Parametry kompilacji, sposób uczenia i ewaluacji możesz pozostawić bez zmian. Czy trafność klasyfikacji wzrosła?\n"]},{"cell_type":"code","metadata":{"id":"7vg2h7-PZGAD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"990ea082-a712-465d-c4ee-6f511a7269f9","executionInfo":{"status":"ok","timestamp":1589129965472,"user_tz":-120,"elapsed":4919,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["model = Sequential()\n","model.add(Embedding(input_dim=1000, output_dim=32, input_length=500))\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(1, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "],"execution_count":34,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n","25000/25000 [==============================] - 1s 52us/step - loss: 3.7444 - accuracy: 0.3882 - val_loss: 0.4727 - val_accuracy: 0.7884\n","Epoch 2/2\n","25000/25000 [==============================] - 1s 46us/step - loss: 5.0353 - accuracy: 0.2889 - val_loss: 2.6558 - val_accuracy: 0.6447\n","25000/25000 [==============================] - 1s 43us/step\n","Trafność klasyfikacji to: 64.47200179100037%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9FkDgnXZGAG","colab_type":"text"},"source":["## Architektury rekurencyjne\n","\n","Aby zamodelować sieć rekurencyjną LSTM bądź GRU - możemy użyć dedykowanych warstw przygotowanych przez autorów Kerasa.\n","\n","\n","**Zadanie 3 (1.25 punktu): Sieć rekurencyjna GRU i LSTM**\n","Aby stworzyć taką sieć utwórz model z następującymi warstwami:\n","\n","<ol>\n","    <li>Warstwa Embedding, analogicznie do poprzednich zadań. Rozmiar wektora embeddingów ustawmy na 32</li>\n","    <li>Warstwa LSTM (https://keras.io/layers/recurrent/) - Warstwa sieci rekurencyjnej - nie potrzebuje wcześniejszego spłaszczenia warstwą Flatten. Ustawmy rozmiar tej warstwy na 32. Ponadto ustawmy parametry dropout i recurrent_dropout na 0.2 (parametr regularyzacyjny zabezpieczający przet przeuczeniem)</li>\n","    <li>Warstwa Dense (wyjściowa) - Warstwa o aktywacji sigmoidalnej z 1 neuronem</li>\n","</ol>\n","\n","Po uruchomieniu sieci wykorzystującej LSTM - zamień warstwę LSTM na GRU (https://keras.io/layers/recurrent/) z takimi samymi parametrami - czy sieć uczy się lepiej? Co z czasem uczenia?"]},{"cell_type":"code","metadata":{"id":"r-z5Se0JZGAG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"outputId":"90c93d3e-9f82-4dc0-ee71-103e83c2ec06","executionInfo":{"status":"error","timestamp":1589132400259,"user_tz":-120,"elapsed":249121,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["import time\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=1000, output_dim=32, input_length=500))\n","model.add(GRU(32, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","start_time = time.time()\n","model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n","end_time = time.time()\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) \n","print(\"Czas treningu: {t}\".format(t=end_time - start_time))\n","\n","# LSTM czas: 385s, accuracy: 82.46%\n","# GRU  czas: 469s, accuracy: 68.72%\n","# dziwne, GRU jest prostsze, wiec powinno sie szybciej uczyc...\n","# no i ten eksplodujacy loss..."],"execution_count":41,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n","25000/25000 [==============================] - 234s 9ms/step - loss: 1136248180687071758835209207808.0000 - accuracy: 0.6733 - val_loss: 0.6289 - val_accuracy: 0.6834\n","Epoch 2/2\n"," 1408/25000 [>.............................] - ETA: 3:27 - loss: 56922502.3258 - accuracy: 0.7663"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-86b04b882e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"DUN5z_vYZGAI","colab_type":"text"},"source":["Jak widzimy siec rekurencyjna daje niższe rezultaty niż sieć feedforward. Dlaczego? \n","Sieci rekurencyjne (LSTM i GRU) dają w wielu zadaniach wyniki, które są najlepsze możliwe. Jednakże trening takiej sieci trwa bardzo długo. Gdybyśmy odpowiednio dobrali liczbę warstw i parametry sieci - prawdopodobnie otrzymalibyśmy najlepsze rezultaty ze wsystkich porównywanych architektur - niestety za cenę czasu, który na laboratoriach jest ograniczony.\n","\n","Ponieważ obliczenia w niektórych architekturach są bardzo intensywne, bardzo popularnym jest wykonywanie tych obliczeń nie na procesorze, a na karcie graficznej. W przypadku posiadania dobrej karty graficznej, szybkość przetwarzania będzie dużo większa.\n","\n","## Architektury konwolucyjne\n","\n","Sieci konwolucyjne w Kerasie zostały już wykorzystane na laboratoriach ze sztucznej inteligencji. Wtedy - używaliśmy ich do detekcji czy obrazek przedstawiony na wejściu sieci reprezentował kota czy psa.\n","\n","Okazuje się, że problemach klasyfikacji tekstu sieci konwolucyjne (CNN - convolutional neural network) radzą sobie również bardzo dobrze (dają niezłe rezultaty, a czas ich uczenia jest zazwyczaj dużo niższy niż sieci rekurencyjnych)!\n","\n","Sprawdźmy jakie rezultaty otrzymamy zaprzęgając sieć konwolucyjną do naszego problemu:\n","\n","**Zadanie 4 (1.25 punktu)**: Przygotuj sieć konwolucyjną wg. następującego schematu:\n","<ol>\n","    <li>Warstwa pierwsza - Warstwa Embedding, analogiczna do poprzednich zadań </li>\n","    <li>Warstwa druga - konwolucja jednowymiarowa. Użyj warstwy Conv1D (https://keras.io/layers/convolutional/) używając 32 filtrów, rozmiaru tzw. kernela = 3, padding ustawmy na 'same', a jako funkcję aktywacji 'relu' </li>\n","    <li>Warstwa trzecia - MaxPooling1D (https://keras.io/layers/convolutional/), ustawmy rozmiar pool_size na 2 </li>\n","    <li>Warstwa czwarta - Flatten - Znów - zamieniamy macierz będącą efektem operacji konwolucji na wektor </li>\n","    <li>Warstwa piąta - Dense, 250 neuronów z aktywacją relu</li>\n","    <li>Warstwa szósta (wyjściowa) - Dense, 1 neuron wyjściowy z aktywacją sigmoidalną (sigmoid)</li>\n","</ol>\n"]},{"cell_type":"code","metadata":{"id":"ple5vphnZGAI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"fb6f97ef-b9fc-4d9a-88cb-743aba48ac97","executionInfo":{"status":"ok","timestamp":1589134064809,"user_tz":-120,"elapsed":5426,"user":{"displayName":"Dariusz Max Adamski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiuGg4VJ5se1vTg8oxApcXcd53c2pNERbwkfOf=s64","userId":"05648663591110704065"}}},"source":["model = Sequential()\n","model.add(Embedding(input_dim=1000, output_dim=32, input_length=500))\n","model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(250, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "],"execution_count":46,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n","25000/25000 [==============================] - 2s 69us/step - loss: 0.4982 - accuracy: 0.7255 - val_loss: 0.3157 - val_accuracy: 0.8640\n","Epoch 2/2\n","25000/25000 [==============================] - 2s 62us/step - loss: 0.2919 - accuracy: 0.8778 - val_loss: 0.2972 - val_accuracy: 0.8731\n","25000/25000 [==============================] - 1s 49us/step\n","Trafność klasyfikacji to: 87.30800151824951%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1enVijEwZGAK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}